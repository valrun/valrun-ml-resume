{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Лабораторная работа №2\n",
    "### Выполнила Рындина Валерия, M33351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Алгоритмы"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### МНК\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def mnk(x, y, tau):\n",
    "    _, n = x.shape\n",
    "    # V, D, U_t = LA.svd(x)\n",
    "    # # V_t = np.transpose(V)\n",
    "    # # U = np.transpose(U_t)\n",
    "    # fi = sum(D[i] / (D[i] ** 2 + tau) * V[i] * U_t.dot(y).sum() for i in range(n))\n",
    "    # return  fi\n",
    "    return np.matmul(\n",
    "        np.matmul(\n",
    "            np.linalg.inv(np.matmul(np.transpose(x), x) + tau * np.identity(n)),\n",
    "            np.transpose(x)\n",
    "        ),\n",
    "        y\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### градиентный спуск"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def mse(y, y_pred):\n",
    "    return (y + y_pred) ** 2\n",
    "\n",
    "def diff_mse(y, y_pred):\n",
    "    return 2.0 * (y_pred - y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def smape(y, y_pred):\n",
    "    return 1.0 * abs(y - y_pred) / (abs(y) + abs(y_pred))\n",
    "\n",
    "def diff_smape(y, y_pred):\n",
    "    return np.sign(y_pred - y) * (abs(y) + abs(y_pred) - np.sign(y_pred) * (y_pred - y)) / (\n",
    "            (abs(y) + abs(y_pred)) ** 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def stochastic_gradient(x, y, diff_L, tau, mu, metric):\n",
    "    n = len(x)\n",
    "    w = [1 / (2 * n) for _ in range(len(x[0]))]\n",
    "\n",
    "    metric_vals = list()\n",
    "    metric_val = 1.\n",
    "    alpha = 1 / 100\n",
    "\n",
    "    for i in range(1000):\n",
    "        step = 1.0 / (i + 1)\n",
    "\n",
    "        diff_multiplier = diff_L(y[i % n], np.dot(w, x[i % n]))\n",
    "        diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
    "        diff_tau = list(diff_i + tau * x_i for x_i, diff_i in zip(x[i % n], diff))\n",
    "\n",
    "        t = list(w_i - d_tau_i * step - mu * d_i for w_i, d_tau_i, d_i in zip(w, diff_tau, diff))\n",
    "\n",
    "        new_metric = sum(metric(y, np.dot(x, w))) /n\n",
    "        metric_val = (1 - alpha) * metric_val + alpha * new_metric\n",
    "        metric_vals.append(metric_val)\n",
    "        w = t\n",
    "    #   L = (1 - alpha) L + alpha * L(np.dot(w, x[i]) * y[i])\n",
    "    return w, metric_vals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Настройка"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# normalize\n",
    "def normalize(dt):\n",
    "    for col in dt.columns :\n",
    "        min_val = min(dt[col])\n",
    "        max_val = max(dt[col])\n",
    "        dt[col] = dt[col].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val != min_val else 0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1    2         3    4         5         6         7    8\n0  0.797509  0.202492  0.0  0.202491  0.0  0.202491  0.202491  0.797509  0.0\n1  0.160068  0.839934  0.0  0.839932  0.0  0.839932  0.839932  0.160068  0.0\n2  0.419145  0.580854  0.0  0.580855  0.0  0.580855  0.580855  0.419145  0.0\n3  0.270965  0.729036  0.0  0.729035  0.0  0.729034  0.729035  0.270965  0.0\n4  0.506731  0.493270  0.0  0.493269  0.0  0.493269  0.493269  0.506731  0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.797509</td>\n      <td>0.202492</td>\n      <td>0.0</td>\n      <td>0.202491</td>\n      <td>0.0</td>\n      <td>0.202491</td>\n      <td>0.202491</td>\n      <td>0.797509</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.160068</td>\n      <td>0.839934</td>\n      <td>0.0</td>\n      <td>0.839932</td>\n      <td>0.0</td>\n      <td>0.839932</td>\n      <td>0.839932</td>\n      <td>0.160068</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.419145</td>\n      <td>0.580854</td>\n      <td>0.0</td>\n      <td>0.580855</td>\n      <td>0.0</td>\n      <td>0.580855</td>\n      <td>0.580855</td>\n      <td>0.419145</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.270965</td>\n      <td>0.729036</td>\n      <td>0.0</td>\n      <td>0.729035</td>\n      <td>0.0</td>\n      <td>0.729034</td>\n      <td>0.729035</td>\n      <td>0.270965</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.506731</td>\n      <td>0.493270</td>\n      <td>0.0</td>\n      <td>0.493269</td>\n      <td>0.0</td>\n      <td>0.493269</td>\n      <td>0.493269</td>\n      <td>0.506731</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/3.txt', 'r') as f:\n",
    "    n = int(f.readline())\n",
    "\n",
    "    n_train = int(f.readline())\n",
    "    x_train = pd.DataFrame(map(lambda it: map(int, it.split(' ')), list(f.readline() for _ in range(n_train))))\n",
    "\n",
    "    n_test = int(f.readline())\n",
    "    x_test = pd.DataFrame(map(lambda it: map(int, it.split(' ')), list(f.readline() for _ in range(n_test))))\n",
    "\n",
    "normalize(x_train)\n",
    "y_train = x_train[n]\n",
    "x_train = x_train.drop(columns=n)\n",
    "\n",
    "normalize(x_test)\n",
    "y_test = x_test[n]\n",
    "x_test = x_test.drop(columns=n)\n",
    "\n",
    "x_train.head()\n",
    "x_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective_mnk(trial, error_fun):\n",
    "    tau = trial.suggest_uniform(\"tau\", 0, 1)\n",
    "\n",
    "    w = mnk(x_train, y_train, tau)\n",
    "    return error_fun(w)\n",
    "\n",
    "def objective_gradient(trial, diff_fun, error_fun, metric):\n",
    "    tau = trial.suggest_uniform(\"tau\", 0, 10)\n",
    "    mu = trial.suggest_uniform(\"alpha\", 0.1, 0.9)\n",
    "\n",
    "    w, _ = stochastic_gradient(x_train, y_train, diff_fun, tau, mu, metric)\n",
    "    return error_fun(w)\n",
    "\n",
    "def error(x, y, error_fun):\n",
    "    def inner(weights):\n",
    "        pred = np.dot(weights, x)\n",
    "        return sum(error_fun(y_i, p_i) for p_i, y_i in zip(pred, y)) / len(x)\n",
    "    return inner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-05-25 18:32:13,140]\u001B[0m A new study created in memory with name: no-name-8a4b47fa-90e6-4c9b-85bf-09ee4e1787f4\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,404]\u001B[0m Trial 0 finished with value: 0.5829443500287073 and parameters: {'tau': 0.24952012841993654}. Best is trial 0 with value: 0.5829443500287073.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,408]\u001B[0m Trial 1 finished with value: 0.5832017952270385 and parameters: {'tau': 0.31518995333452926}. Best is trial 0 with value: 0.5829443500287073.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,414]\u001B[0m Trial 2 finished with value: 0.5847849999053873 and parameters: {'tau': 0.741657565937292}. Best is trial 0 with value: 0.5829443500287073.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,418]\u001B[0m Trial 3 finished with value: 0.5825308306613608 and parameters: {'tau': 0.14605099691885826}. Best is trial 3 with value: 0.5825308306613608.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,428]\u001B[0m Trial 4 finished with value: 0.5831682672238144 and parameters: {'tau': 0.3065820709074044}. Best is trial 3 with value: 0.5825308306613608.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,440]\u001B[0m Trial 5 finished with value: 0.5838956141909863 and parameters: {'tau': 0.49715454720388164}. Best is trial 3 with value: 0.5825308306613608.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,448]\u001B[0m Trial 6 finished with value: 0.5829034540162464 and parameters: {'tau': 0.2391777131063919}. Best is trial 3 with value: 0.5825308306613608.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,456]\u001B[0m Trial 7 finished with value: 0.5829322890353106 and parameters: {'tau': 0.24646742830378532}. Best is trial 3 with value: 0.5825308306613608.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,463]\u001B[0m Trial 8 finished with value: 0.5844705207769005 and parameters: {'tau': 0.6537012099924321}. Best is trial 3 with value: 0.5825308306613608.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,469]\u001B[0m Trial 9 finished with value: 0.5848141567914751 and parameters: {'tau': 0.7498981564114989}. Best is trial 3 with value: 0.5825308306613608.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,481]\u001B[0m Trial 10 finished with value: 0.5821094960719617 and parameters: {'tau': 0.04309957604522677}. Best is trial 10 with value: 0.5821094960719617.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,510]\u001B[0m Trial 11 finished with value: 0.5820959897092465 and parameters: {'tau': 0.0398396619093359}. Best is trial 11 with value: 0.5820959897092465.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,527]\u001B[0m Trial 12 finished with value: 0.5819806378442706 and parameters: {'tau': 0.012098297951422317}. Best is trial 12 with value: 0.5819806378442706.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,539]\u001B[0m Trial 13 finished with value: 0.582113980024348 and parameters: {'tau': 0.04418237582305463}. Best is trial 12 with value: 0.5819806378442706.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,556]\u001B[0m Trial 14 finished with value: 0.58554367020842 and parameters: {'tau': 0.9609872088630134}. Best is trial 12 with value: 0.5819806378442706.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,580]\u001B[0m Trial 15 finished with value: 0.5836805890573818 and parameters: {'tau': 0.4399663471869928}. Best is trial 12 with value: 0.5819806378442706.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,594]\u001B[0m Trial 16 finished with value: 0.5820535937743726 and parameters: {'tau': 0.029622954437375615}. Best is trial 12 with value: 0.5819806378442706.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,605]\u001B[0m Trial 17 finished with value: 0.5824896353158588 and parameters: {'tau': 0.13587638640048144}. Best is trial 12 with value: 0.5819806378442706.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,621]\u001B[0m Trial 18 finished with value: 0.5834415150348176 and parameters: {'tau': 0.37722601085963303}. Best is trial 12 with value: 0.5819806378442706.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,642]\u001B[0m Trial 19 finished with value: 0.5825462081516996 and parameters: {'tau': 0.14985511081392605}. Best is trial 12 with value: 0.5819806378442706.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,656]\u001B[0m Trial 20 finished with value: 0.5842532639692369 and parameters: {'tau': 0.5939076101001882}. Best is trial 12 with value: 0.5819806378442706.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,670]\u001B[0m Trial 21 finished with value: 0.5819621864228649 and parameters: {'tau': 0.007677111818887014}. Best is trial 21 with value: 0.5819621864228649.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,679]\u001B[0m Trial 22 finished with value: 0.5819320871735641 and parameters: {'tau': 0.0004556537360263617}. Best is trial 22 with value: 0.5819320871735641.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,704]\u001B[0m Trial 23 finished with value: 0.5824695664956643 and parameters: {'tau': 0.13092831982889291}. Best is trial 22 with value: 0.5819320871735641.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,721]\u001B[0m Trial 24 finished with value: 0.5823626821390389 and parameters: {'tau': 0.10467014353654355}. Best is trial 22 with value: 0.5819320871735641.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,735]\u001B[0m Trial 25 finished with value: 0.5820027916172457 and parameters: {'tau': 0.017412349101265115}. Best is trial 22 with value: 0.5819320871735641.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,748]\u001B[0m Trial 26 finished with value: 0.5827493975684779 and parameters: {'tau': 0.20043486173025096}. Best is trial 22 with value: 0.5819320871735641.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,768]\u001B[0m Trial 27 finished with value: 0.582273166573035 and parameters: {'tau': 0.08280088014962445}. Best is trial 22 with value: 0.5819320871735641.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,788]\u001B[0m Trial 28 finished with value: 0.5819310475581718 and parameters: {'tau': 0.00017247224950660799}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,802]\u001B[0m Trial 29 finished with value: 0.5831827847090865 and parameters: {'tau': 0.3103071946917313}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,813]\u001B[0m Trial 30 finished with value: 0.5855021892407298 and parameters: {'tau': 0.9487252194629083}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,839]\u001B[0m Trial 31 finished with value: 0.5826946816976386 and parameters: {'tau': 0.18675671993502968}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,858]\u001B[0m Trial 32 finished with value: 0.5819582360824365 and parameters: {'tau': 0.006731077700122454}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,874]\u001B[0m Trial 33 finished with value: 0.5822696715424711 and parameters: {'tau': 0.08194926240420783}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,886]\u001B[0m Trial 34 finished with value: 0.5827104862105551 and parameters: {'tau': 0.19070321583975744}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,914]\u001B[0m Trial 35 finished with value: 0.5822784637676947 and parameters: {'tau': 0.08409194325295476}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,930]\u001B[0m Trial 36 finished with value: 0.5852354004935155 and parameters: {'tau': 0.870618728458801}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,943]\u001B[0m Trial 37 finished with value: 0.5819425882561096 and parameters: {'tau': 0.0029846696656929323}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,956]\u001B[0m Trial 38 finished with value: 0.5830792962982375 and parameters: {'tau': 0.2838207748989295}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:13,984]\u001B[0m Trial 39 finished with value: 0.5819344155858134 and parameters: {'tau': 9.39357987754649e-06}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,001]\u001B[0m Trial 40 finished with value: 0.5828402086899471 and parameters: {'tau': 0.22323104203015431}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,014]\u001B[0m Trial 41 finished with value: 0.5822769839866857 and parameters: {'tau': 0.08373124353870962}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,025]\u001B[0m Trial 42 finished with value: 0.5825196993430907 and parameters: {'tau': 0.14329938454502283}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,038]\u001B[0m Trial 43 finished with value: 0.5819630469331438 and parameters: {'tau': 0.007883210419628606}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,062]\u001B[0m Trial 44 finished with value: 0.5821852551386919 and parameters: {'tau': 0.061430841204399046}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,077]\u001B[0m Trial 45 finished with value: 0.582410982296765 and parameters: {'tau': 0.1165162944974918}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,089]\u001B[0m Trial 46 finished with value: 0.5829860915717442 and parameters: {'tau': 0.260101505440499}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,099]\u001B[0m Trial 47 finished with value: 0.5834171566616219 and parameters: {'tau': 0.37088279184443884}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,117]\u001B[0m Trial 48 finished with value: 0.5841462371063542 and parameters: {'tau': 0.5647373311206203}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,138]\u001B[0m Trial 49 finished with value: 0.582170447937726 and parameters: {'tau': 0.05784182644757667}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,153]\u001B[0m Trial 50 finished with value: 0.5821439224014986 and parameters: {'tau': 0.05141996050106916}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,165]\u001B[0m Trial 51 finished with value: 0.5819519343765314 and parameters: {'tau': 0.005222235861466686}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,189]\u001B[0m Trial 52 finished with value: 0.5819483813079089 and parameters: {'tau': 0.004371619980580683}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,207]\u001B[0m Trial 53 finished with value: 0.5826192205340918 and parameters: {'tau': 0.16796256971847626}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,220]\u001B[0m Trial 54 finished with value: 0.581953956471225 and parameters: {'tau': 0.005706359592422766}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,231]\u001B[0m Trial 55 finished with value: 0.5824232646489625 and parameters: {'tau': 0.11953385221155928}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,246]\u001B[0m Trial 56 finished with value: 0.5820833100322516 and parameters: {'tau': 0.036781526485131506}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,270]\u001B[0m Trial 57 finished with value: 0.5821499680135663 and parameters: {'tau': 0.05288276759347667}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,286]\u001B[0m Trial 58 finished with value: 0.5823793869820161 and parameters: {'tau': 0.10876352649334721}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,298]\u001B[0m Trial 59 finished with value: 0.5819352796470046 and parameters: {'tau': 0.001232218466695807}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,320]\u001B[0m Trial 60 finished with value: 0.5848338507160084 and parameters: {'tau': 0.7554725664048865}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,339]\u001B[0m Trial 61 finished with value: 0.5819533937237114 and parameters: {'tau': 0.005571625523714081}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,353]\u001B[0m Trial 62 finished with value: 0.5822200643374867 and parameters: {'tau': 0.06987980268003113}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,364]\u001B[0m Trial 63 finished with value: 0.5820938385180484 and parameters: {'tau': 0.03932067566932338}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,390]\u001B[0m Trial 64 finished with value: 0.5823420502540012 and parameters: {'tau': 0.09961981124076295}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,407]\u001B[0m Trial 65 finished with value: 0.5819380940246843 and parameters: {'tau': 0.0019079622138024263}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,420]\u001B[0m Trial 66 finished with value: 0.5826241115121714 and parameters: {'tau': 0.1691782524352688}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,437]\u001B[0m Trial 67 finished with value: 0.5820696326639152 and parameters: {'tau': 0.03348520177712808}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,463]\u001B[0m Trial 68 finished with value: 0.5825355171103904 and parameters: {'tau': 0.1472099874243004}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,479]\u001B[0m Trial 69 finished with value: 0.5822453906498967 and parameters: {'tau': 0.07603748713600422}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,490]\u001B[0m Trial 70 finished with value: 0.5820819799225321 and parameters: {'tau': 0.03646085136093158}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,515]\u001B[0m Trial 71 finished with value: 0.5819703799696083 and parameters: {'tau': 0.009639873409785945}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,534]\u001B[0m Trial 72 finished with value: 0.5820748905776237 and parameters: {'tau': 0.03475209019694743}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,546]\u001B[0m Trial 73 finished with value: 0.5823522806724881 and parameters: {'tau': 0.10212330551755099}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,558]\u001B[0m Trial 74 finished with value: 0.581940400700061 and parameters: {'tau': 0.0024607502453949186}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,585]\u001B[0m Trial 75 finished with value: 0.582244587090661 and parameters: {'tau': 0.07584197950274262}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,603]\u001B[0m Trial 76 finished with value: 0.5821809051344473 and parameters: {'tau': 0.06037616337244937}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,618]\u001B[0m Trial 77 finished with value: 0.5838562650011326 and parameters: {'tau': 0.4866347974482104}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,648]\u001B[0m Trial 78 finished with value: 0.5819378924557024 and parameters: {'tau': 0.001859628110418228}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,663]\u001B[0m Trial 79 finished with value: 0.5828210353383648 and parameters: {'tau': 0.2184080985999448}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,675]\u001B[0m Trial 80 finished with value: 0.5824648137180033 and parameters: {'tau': 0.12975732465223994}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,697]\u001B[0m Trial 81 finished with value: 0.5820461734842183 and parameters: {'tau': 0.027837283409836322}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,718]\u001B[0m Trial 82 finished with value: 0.5822953235917196 and parameters: {'tau': 0.08820368991343219}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,731]\u001B[0m Trial 83 finished with value: 0.5819454913510448 and parameters: {'tau': 0.003679757725272942}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,745]\u001B[0m Trial 84 finished with value: 0.5821713148789048 and parameters: {'tau': 0.05805187584602544}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,773]\u001B[0m Trial 85 finished with value: 0.5820325341084742 and parameters: {'tau': 0.024556939416511242}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,791]\u001B[0m Trial 86 finished with value: 0.5820583224537939 and parameters: {'tau': 0.030761284185028624}. Best is trial 28 with value: 0.5819310475581718.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,806]\u001B[0m Trial 87 finished with value: 0.5819309179640789 and parameters: {'tau': 0.00010910164996842837}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,835]\u001B[0m Trial 88 finished with value: 0.5823476874274398 and parameters: {'tau': 0.10099910940416561}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,853]\u001B[0m Trial 89 finished with value: 0.5821682549002718 and parameters: {'tau': 0.057310525671090906}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,867]\u001B[0m Trial 90 finished with value: 0.5847184996987232 and parameters: {'tau': 0.7229175278450857}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,892]\u001B[0m Trial 91 finished with value: 0.5819443631194882 and parameters: {'tau': 0.003409641313952116}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,916]\u001B[0m Trial 92 finished with value: 0.5819334729438048 and parameters: {'tau': 0.0007959741950340133}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,930]\u001B[0m Trial 93 finished with value: 0.5833746002037948 and parameters: {'tau': 0.3598221866618971}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,941]\u001B[0m Trial 94 finished with value: 0.5820659672904458 and parameters: {'tau': 0.0326022549919049}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,970]\u001B[0m Trial 95 finished with value: 0.5822114054967978 and parameters: {'tau': 0.06777656175970266}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,986]\u001B[0m Trial 96 finished with value: 0.582135105573376 and parameters: {'tau': 0.049287516541722864}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:14,999]\u001B[0m Trial 97 finished with value: 0.5820424698084342 and parameters: {'tau': 0.026946281957388567}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:15,009]\u001B[0m Trial 98 finished with value: 0.5824443429266062 and parameters: {'tau': 0.1247173149142339}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:15,037]\u001B[0m Trial 99 finished with value: 0.5825994480611748 and parameters: {'tau': 0.16305145317985284}. Best is trial 87 with value: 0.5819309179640789.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MNK\n",
      "Number of finished trials: 100\n",
      "Best trial: {'tau': 0.00010910164996842837}\n",
      "Best score: 0.5819309179640789\n"
     ]
    }
   ],
   "source": [
    "studyMNK = optuna.create_study(direction='minimize')\n",
    "studyMNK.optimize(lambda trial : objective_mnk(trial, error(x_train, y_train, smape)), n_trials=100)\n",
    "\n",
    "print('Testing MNK')\n",
    "print('Number of finished trials:', len(studyMNK.trials))\n",
    "print('Best trial:', studyMNK.best_trial.params)\n",
    "print('Best score:', studyMNK.best_trial.value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-05-25 18:32:15,065]\u001B[0m A new study created in memory with name: no-name-86ff14b5-8cad-4862-9c5c-88bb6f76557c\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:15,368]\u001B[0m Trial 0 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:2: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return (y + y_pred) ** 2\n",
      "\u001B[32m[I 2022-05-25 18:32:15,663]\u001B[0m Trial 1 finished with value: inf and parameters: {'tau': 2.909191428985637, 'alpha': 0.6497170010179221}. Best is trial 1 with value: inf.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:15,952]\u001B[0m Trial 2 finished with value: 0.9958594159709863 and parameters: {'tau': 6.710102003818958, 'alpha': 0.12477564310244978}. Best is trial 2 with value: 0.9958594159709863.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:2: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return (y + y_pred) ** 2\n",
      "\u001B[32m[I 2022-05-25 18:32:16,217]\u001B[0m Trial 3 finished with value: inf and parameters: {'tau': 4.5975512755450465, 'alpha': 0.4953792864775577}. Best is trial 2 with value: 0.9958594159709863.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:16,449]\u001B[0m Trial 4 finished with value: 2.990367563888284e+87 and parameters: {'tau': 0.2659520595464149, 'alpha': 0.35945745854980016}. Best is trial 2 with value: 0.9958594159709863.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:2: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return (y + y_pred) ** 2\n",
      "\u001B[32m[I 2022-05-25 18:32:16,642]\u001B[0m Trial 5 finished with value: inf and parameters: {'tau': 0.3826989910159351, 'alpha': 0.688443692000356}. Best is trial 2 with value: 0.9958594159709863.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:16,861]\u001B[0m Trial 6 finished with value: 1.0958789436390417 and parameters: {'tau': 8.468338270433195, 'alpha': 0.23448363364417393}. Best is trial 2 with value: 0.9958594159709863.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:17,069]\u001B[0m Trial 7 finished with value: 0.965697955890083 and parameters: {'tau': 8.784825739149738, 'alpha': 0.10923108941074987}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:17,241]\u001B[0m Trial 8 finished with value: 1.0177317249503701 and parameters: {'tau': 3.7549854233380375, 'alpha': 0.16726347195995056}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:2: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return (y + y_pred) ** 2\n",
      "\u001B[32m[I 2022-05-25 18:32:17,417]\u001B[0m Trial 9 finished with value: inf and parameters: {'tau': 8.616332731479483, 'alpha': 0.7302873894378539}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:2: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return (y + y_pred) ** 2\n",
      "\u001B[32m[I 2022-05-25 18:32:17,602]\u001B[0m Trial 10 finished with value: inf and parameters: {'tau': 3.7773360230708897, 'alpha': 0.7023857970541755}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:17,769]\u001B[0m Trial 11 finished with value: 3.841928268834653e+142 and parameters: {'tau': 9.952727848730909, 'alpha': 0.38922531622427176}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:17,960]\u001B[0m Trial 12 finished with value: 0.990501286480547 and parameters: {'tau': 6.636964879472263, 'alpha': 0.11894847450889656}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:18,135]\u001B[0m Trial 13 finished with value: 7.227904309044328 and parameters: {'tau': 6.465713850683111, 'alpha': 0.27556099681846785}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:18,352]\u001B[0m Trial 14 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:18,567]\u001B[0m Trial 15 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:18,785]\u001B[0m Trial 16 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:19,082]\u001B[0m Trial 17 finished with value: 0.9710243772399656 and parameters: {'tau': 6.6754705594595904, 'alpha': 0.10362290094225977}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:19,342]\u001B[0m Trial 18 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:2: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return (y + y_pred) ** 2\n",
      "\u001B[32m[I 2022-05-25 18:32:19,624]\u001B[0m Trial 19 finished with value: inf and parameters: {'tau': 8.130353755881371, 'alpha': 0.527620789843435}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:19,880]\u001B[0m Trial 20 finished with value: 4.378426624474027 and parameters: {'tau': 9.815548735416472, 'alpha': 0.2706294912274081}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:20,091]\u001B[0m Trial 21 finished with value: 6.938621446116918e+128 and parameters: {'tau': 5.684523902615607, 'alpha': 0.3819520080070935}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:20,302]\u001B[0m Trial 22 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:20,555]\u001B[0m Trial 23 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:20,828]\u001B[0m Trial 24 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:21,058]\u001B[0m Trial 25 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:21,292]\u001B[0m Trial 26 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:21,546]\u001B[0m Trial 27 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:21,811]\u001B[0m Trial 28 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:22,156]\u001B[0m Trial 29 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:22,444]\u001B[0m Trial 30 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:22,760]\u001B[0m Trial 31 finished with value: 0.9907152375329016 and parameters: {'tau': 7.519044539633436, 'alpha': 0.18920589706223573}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:23,140]\u001B[0m Trial 32 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:23,579]\u001B[0m Trial 33 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:23,888]\u001B[0m Trial 34 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:2: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return (y + y_pred) ** 2\n",
      "\u001B[32m[I 2022-05-25 18:32:24,184]\u001B[0m Trial 35 finished with value: inf and parameters: {'tau': 5.414322548545407, 'alpha': 0.5158176175097248}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:24,593]\u001B[0m Trial 36 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:24,909]\u001B[0m Trial 37 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:25,182]\u001B[0m Trial 38 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:25,564]\u001B[0m Trial 39 finished with value: 23074116.15017189 and parameters: {'tau': 1.9418960130063407, 'alpha': 0.2944483430023914}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:25,847]\u001B[0m Trial 40 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:2: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return (y + y_pred) ** 2\n",
      "\u001B[32m[I 2022-05-25 18:32:26,185]\u001B[0m Trial 41 finished with value: inf and parameters: {'tau': 9.022675052571817, 'alpha': 0.5937123007944081}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:26,507]\u001B[0m Trial 42 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:26,841]\u001B[0m Trial 43 finished with value: 0.982407835197416 and parameters: {'tau': 7.015393156915006, 'alpha': 0.11379078289866458}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:27,190]\u001B[0m Trial 44 finished with value: 0.9939333721997562 and parameters: {'tau': 7.37212039885568, 'alpha': 0.18483478482439558}. Best is trial 7 with value: 0.965697955890083.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:27,570]\u001B[0m Trial 45 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:27,904]\u001B[0m Trial 46 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:28,204]\u001B[0m Trial 47 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:28,481]\u001B[0m Trial 48 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:28,758]\u001B[0m Trial 49 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:29,022]\u001B[0m Trial 50 finished with value: 0.9640725458354191 and parameters: {'tau': 7.4167290475337255, 'alpha': 0.10219946173782557}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:29,350]\u001B[0m Trial 51 finished with value: 1.0056858623775187 and parameters: {'tau': 5.959555210424898, 'alpha': 0.2186526729602421}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:29,735]\u001B[0m Trial 52 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:30,100]\u001B[0m Trial 53 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:30,445]\u001B[0m Trial 54 finished with value: 0.9700900532334522 and parameters: {'tau': 7.712367637198944, 'alpha': 0.10763473977260485}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:30,750]\u001B[0m Trial 55 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:31,109]\u001B[0m Trial 56 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:31,475]\u001B[0m Trial 57 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:31,808]\u001B[0m Trial 58 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:32,188]\u001B[0m Trial 59 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:32,538]\u001B[0m Trial 60 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:32,963]\u001B[0m Trial 61 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:33,264]\u001B[0m Trial 62 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:33,609]\u001B[0m Trial 63 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:33,984]\u001B[0m Trial 64 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:34,331]\u001B[0m Trial 65 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:34,655]\u001B[0m Trial 66 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:34,935]\u001B[0m Trial 67 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:35,263]\u001B[0m Trial 68 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:35,529]\u001B[0m Trial 69 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:35,853]\u001B[0m Trial 70 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:36,133]\u001B[0m Trial 71 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:36,421]\u001B[0m Trial 72 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:36,842]\u001B[0m Trial 73 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:37,138]\u001B[0m Trial 74 finished with value: 5.891232508958793e+45 and parameters: {'tau': 9.252423365944662, 'alpha': 0.3286537123698237}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:37,444]\u001B[0m Trial 75 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:37,839]\u001B[0m Trial 76 finished with value: 1.268707340590556e+241 and parameters: {'tau': 7.989384431650835, 'alpha': 0.44596926363408496}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:38,265]\u001B[0m Trial 77 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:38,678]\u001B[0m Trial 78 finished with value: 0.9995525186481083 and parameters: {'tau': 7.761274250592726, 'alpha': 0.1732134188331211}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:39,101]\u001B[0m Trial 79 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:39,400]\u001B[0m Trial 80 finished with value: 1.0843882581836113 and parameters: {'tau': 9.026269388172787, 'alpha': 0.2334963452890803}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:39,741]\u001B[0m Trial 81 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:40,084]\u001B[0m Trial 82 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:2: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return (y + y_pred) ** 2\n",
      "\u001B[32m[I 2022-05-25 18:32:40,408]\u001B[0m Trial 83 finished with value: inf and parameters: {'tau': 9.357374561255254, 'alpha': 0.599631476881154}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:40,769]\u001B[0m Trial 84 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:41,091]\u001B[0m Trial 85 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:41,398]\u001B[0m Trial 86 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:41,728]\u001B[0m Trial 87 finished with value: 0.970174334225316 and parameters: {'tau': 6.35088857097761, 'alpha': 0.10155250470755856}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:42,077]\u001B[0m Trial 88 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:42,364]\u001B[0m Trial 89 finished with value: 1.0173542612797766 and parameters: {'tau': 4.846599682765188, 'alpha': 0.1512060753610349}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:42,825]\u001B[0m Trial 90 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:43,209]\u001B[0m Trial 91 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:43,544]\u001B[0m Trial 92 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:43,870]\u001B[0m Trial 93 finished with value: 0.987190638305672 and parameters: {'tau': 6.220830944328552, 'alpha': 0.11383379636816834}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:44,200]\u001B[0m Trial 94 finished with value: 1.0080344983525418 and parameters: {'tau': 7.217440544339491, 'alpha': 0.22046883857502353}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:44,488]\u001B[0m Trial 95 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:44,796]\u001B[0m Trial 96 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:45,147]\u001B[0m Trial 97 finished with value: 1.0017760531588613 and parameters: {'tau': 8.416327551435263, 'alpha': 0.15199388870122774}. Best is trial 50 with value: 0.9640725458354191.\u001B[0m\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:45,457]\u001B[0m Trial 98 failed, because the objective function returned nan.\u001B[0m\n",
      "/tmp/ipykernel_26423/1618380470.py:5: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 2.0 * (y_pred - y)\n",
      "/tmp/ipykernel_26423/1019279531.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff = list(x_i * diff_multiplier for x_i in x[i % n])\n",
      "\u001B[33m[W 2022-05-25 18:32:45,745]\u001B[0m Trial 99 failed, because the objective function returned nan.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSE gradient\n",
      "Number of finished trials: 100\n",
      "Best trial: {'tau': 7.4167290475337255, 'alpha': 0.10219946173782557}\n",
      "Best score: 0.9640725458354191\n"
     ]
    }
   ],
   "source": [
    "studyMSE = optuna.create_study(direction='minimize')\n",
    "studyMSE.optimize(lambda trial : objective_gradient(trial, diff_mse, error(x_train, y_train, mse), mse), n_trials=100)\n",
    "\n",
    "\n",
    "print('Testing MSE gradient')\n",
    "print('Number of finished trials:', len(studyMSE.trials))\n",
    "print('Best trial:', studyMSE.best_trial.params)\n",
    "print('Best score:', studyMSE.best_trial.value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-05-25 18:32:45,763]\u001B[0m A new study created in memory with name: no-name-18cc455b-8aec-4541-9792-f05fceb94ef7\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:46,607]\u001B[0m Trial 0 finished with value: 1.0 and parameters: {'tau': 5.211108678983783, 'alpha': 0.6722432213272935}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:47,347]\u001B[0m Trial 1 finished with value: 1.0 and parameters: {'tau': 3.534641257206408, 'alpha': 0.833033402591652}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:48,022]\u001B[0m Trial 2 finished with value: 1.0 and parameters: {'tau': 2.7542441472505477, 'alpha': 0.7966288178333027}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:48,595]\u001B[0m Trial 3 finished with value: 1.0 and parameters: {'tau': 0.656539404308274, 'alpha': 0.48903504355728844}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:49,200]\u001B[0m Trial 4 finished with value: 1.0 and parameters: {'tau': 5.947251442082986, 'alpha': 0.7549358207603288}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:49,623]\u001B[0m Trial 5 finished with value: 1.0 and parameters: {'tau': 9.393485990134392, 'alpha': 0.45147573459110657}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:50,203]\u001B[0m Trial 6 finished with value: 1.0 and parameters: {'tau': 2.925826436194272, 'alpha': 0.5714548107343728}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:50,754]\u001B[0m Trial 7 finished with value: 1.0 and parameters: {'tau': 7.803550932630001, 'alpha': 0.6907644819578074}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:51,275]\u001B[0m Trial 8 finished with value: 1.0 and parameters: {'tau': 7.810304180500575, 'alpha': 0.16789764713675093}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:51,770]\u001B[0m Trial 9 finished with value: 1.0 and parameters: {'tau': 0.9331588544079972, 'alpha': 0.20269240779741207}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:52,317]\u001B[0m Trial 10 finished with value: 1.0 and parameters: {'tau': 5.36832327652666, 'alpha': 0.3441930390501352}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:52,850]\u001B[0m Trial 11 finished with value: 1.0 and parameters: {'tau': 3.7495075441171997, 'alpha': 0.8955736584163065}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:53,380]\u001B[0m Trial 12 finished with value: 1.0 and parameters: {'tau': 4.3765168966713635, 'alpha': 0.6375912156192646}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:53,955]\u001B[0m Trial 13 finished with value: 1.0 and parameters: {'tau': 6.485409998336492, 'alpha': 0.8973985703546036}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:54,489]\u001B[0m Trial 14 finished with value: 1.0 and parameters: {'tau': 2.678428597484564, 'alpha': 0.7692961350379082}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:55,020]\u001B[0m Trial 15 finished with value: 1.0 and parameters: {'tau': 1.6649545530568295, 'alpha': 0.6185458963421803}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:55,542]\u001B[0m Trial 16 finished with value: 1.0 and parameters: {'tau': 4.477114897963684, 'alpha': 0.7209573852614265}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:56,096]\u001B[0m Trial 17 finished with value: 1.0 and parameters: {'tau': 2.1079114144899993, 'alpha': 0.39628520258717503}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:56,596]\u001B[0m Trial 18 finished with value: 1.0 and parameters: {'tau': 0.10282001867527413, 'alpha': 0.5846729358218107}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:57,131]\u001B[0m Trial 19 finished with value: 1.0 and parameters: {'tau': 7.276259820383398, 'alpha': 0.7166809596695072}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:57,642]\u001B[0m Trial 20 finished with value: 1.0 and parameters: {'tau': 9.993925218793105, 'alpha': 0.3938353820222951}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:58,199]\u001B[0m Trial 21 finished with value: 0.6186870899071061 and parameters: {'tau': 0.018694843774583164, 'alpha': 0.31089573877239773}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:58,714]\u001B[0m Trial 22 finished with value: 1.0 and parameters: {'tau': 0.13549393077026683, 'alpha': 0.5514994184873053}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:59,260]\u001B[0m Trial 23 finished with value: 1.0 and parameters: {'tau': 9.38349332929286, 'alpha': 0.25672514576580785}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:32:59,857]\u001B[0m Trial 24 finished with value: 1.0 and parameters: {'tau': 9.82512320390825, 'alpha': 0.3099206944303166}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:00,331]\u001B[0m Trial 25 finished with value: 0.7964012081508293 and parameters: {'tau': 0.05051468564771447, 'alpha': 0.532736543507556}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:00,823]\u001B[0m Trial 26 finished with value: 1.0 and parameters: {'tau': 1.2906430050434419, 'alpha': 0.10035351959082031}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:01,319]\u001B[0m Trial 27 finished with value: 1.0 and parameters: {'tau': 1.645916451817073, 'alpha': 0.5087202933274234}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:01,837]\u001B[0m Trial 28 finished with value: 1.0 and parameters: {'tau': 4.971163905156114, 'alpha': 0.6627350468241154}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:02,367]\u001B[0m Trial 29 finished with value: 1.0 and parameters: {'tau': 3.4339579967722, 'alpha': 0.4240594136849615}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:02,957]\u001B[0m Trial 30 finished with value: 1.0 and parameters: {'tau': 6.303890172280133, 'alpha': 0.32302210752625127}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:03,388]\u001B[0m Trial 31 finished with value: 1.0 and parameters: {'tau': 4.205178448473523, 'alpha': 0.6625035878800613}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:03,870]\u001B[0m Trial 32 finished with value: 1.0 and parameters: {'tau': 3.355765285013647, 'alpha': 0.4413730261215101}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:04,504]\u001B[0m Trial 33 finished with value: 1.0 and parameters: {'tau': 6.774590446752596, 'alpha': 0.3305454784908833}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:04,993]\u001B[0m Trial 34 finished with value: 1.0 and parameters: {'tau': 0.6265778256102603, 'alpha': 0.5275203873034358}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:05,458]\u001B[0m Trial 35 finished with value: 1.0 and parameters: {'tau': 8.274470901450853, 'alpha': 0.39273028243732677}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:05,944]\u001B[0m Trial 36 finished with value: 1.0 and parameters: {'tau': 8.762257099428895, 'alpha': 0.47816260177272984}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:06,407]\u001B[0m Trial 37 finished with value: 1.0 and parameters: {'tau': 2.232562213365229, 'alpha': 0.25205598643149346}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:06,879]\u001B[0m Trial 38 finished with value: 1.0 and parameters: {'tau': 0.2513063177290511, 'alpha': 0.5667353520861994}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:07,478]\u001B[0m Trial 39 finished with value: 1.0 and parameters: {'tau': 0.7710699930332839, 'alpha': 0.5505625519159397}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:08,028]\u001B[0m Trial 40 finished with value: 1.0 and parameters: {'tau': 0.06464259846472722, 'alpha': 0.8121742566289633}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:08,498]\u001B[0m Trial 41 finished with value: 1.0 and parameters: {'tau': 1.25689174895709, 'alpha': 0.2733557909366982}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:08,995]\u001B[0m Trial 42 finished with value: 1.0 and parameters: {'tau': 9.22337316624266, 'alpha': 0.10556466874226296}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:09,511]\u001B[0m Trial 43 finished with value: 1.0 and parameters: {'tau': 9.927898455525522, 'alpha': 0.10000462530390741}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:10,123]\u001B[0m Trial 44 finished with value: 1.0 and parameters: {'tau': 1.4015179958568778, 'alpha': 0.18480871025136303}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:10,670]\u001B[0m Trial 45 finished with value: 1.0 and parameters: {'tau': 1.8130233844080517, 'alpha': 0.5153308585191664}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:11,172]\u001B[0m Trial 46 finished with value: 1.0 and parameters: {'tau': 5.598378927318931, 'alpha': 0.13217498360327118}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:11,689]\u001B[0m Trial 47 finished with value: 1.0 and parameters: {'tau': 0.9133614097796996, 'alpha': 0.475643708914027}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:12,158]\u001B[0m Trial 48 finished with value: 1.0 and parameters: {'tau': 2.3734134083540104, 'alpha': 0.5997781947827869}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:12,645]\u001B[0m Trial 49 finished with value: 1.0 and parameters: {'tau': 3.6257753965763735, 'alpha': 0.43085317282802016}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:13,132]\u001B[0m Trial 50 finished with value: 1.0 and parameters: {'tau': 4.8662533265318615, 'alpha': 0.35744857097270694}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:13,611]\u001B[0m Trial 51 finished with value: 1.0 and parameters: {'tau': 4.107680752912965, 'alpha': 0.6931512702611292}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:14,236]\u001B[0m Trial 52 finished with value: 1.0 and parameters: {'tau': 5.856817094267599, 'alpha': 0.6438722233795506}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:14,873]\u001B[0m Trial 53 finished with value: 1.0 and parameters: {'tau': 6.342668201800854, 'alpha': 0.29540414662012515}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:15,473]\u001B[0m Trial 54 finished with value: 1.0 and parameters: {'tau': 5.3390943199566205, 'alpha': 0.7609619723424357}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:16,040]\u001B[0m Trial 55 finished with value: 1.0 and parameters: {'tau': 3.137834453193123, 'alpha': 0.3651421196324494}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:16,728]\u001B[0m Trial 56 finished with value: 1.0 and parameters: {'tau': 7.038161226229361, 'alpha': 0.21395818217766227}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:17,299]\u001B[0m Trial 57 finished with value: 1.0 and parameters: {'tau': 4.174670208375695, 'alpha': 0.6151536040072716}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:17,970]\u001B[0m Trial 58 finished with value: 1.0 and parameters: {'tau': 0.4101434963711684, 'alpha': 0.44662938523677187}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:18,633]\u001B[0m Trial 59 finished with value: 1.0 and parameters: {'tau': 0.509419496701879, 'alpha': 0.508471136677953}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:19,229]\u001B[0m Trial 60 finished with value: 1.0 and parameters: {'tau': 7.8191556336571235, 'alpha': 0.38216478458627423}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:19,802]\u001B[0m Trial 61 finished with value: 1.0 and parameters: {'tau': 8.600768035177023, 'alpha': 0.47384796204541596}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:20,398]\u001B[0m Trial 62 finished with value: 1.0 and parameters: {'tau': 8.51362506138503, 'alpha': 0.2630804556641374}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:20,987]\u001B[0m Trial 63 finished with value: 1.0 and parameters: {'tau': 8.378404702494498, 'alpha': 0.40866254404581487}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:21,572]\u001B[0m Trial 64 finished with value: 1.0 and parameters: {'tau': 2.633154319149309, 'alpha': 0.5625018918385393}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:22,180]\u001B[0m Trial 65 finished with value: 1.0 and parameters: {'tau': 0.2665687676888666, 'alpha': 0.22986636179568534}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:22,771]\u001B[0m Trial 66 finished with value: 1.0 and parameters: {'tau': 1.0048382480823719, 'alpha': 0.5493609687297673}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:23,396]\u001B[0m Trial 67 finished with value: 1.0 and parameters: {'tau': 0.790460390555983, 'alpha': 0.7286814489856637}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:23,991]\u001B[0m Trial 68 finished with value: 1.0 and parameters: {'tau': 0.011465444026828975, 'alpha': 0.8370445490480257}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:24,624]\u001B[0m Trial 69 finished with value: 1.0 and parameters: {'tau': 1.7129951482631491, 'alpha': 0.15456052124366518}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:25,254]\u001B[0m Trial 70 finished with value: 1.0 and parameters: {'tau': 2.190933340012645, 'alpha': 0.5926375995583225}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:25,873]\u001B[0m Trial 71 finished with value: 1.0 and parameters: {'tau': 5.071077467330746, 'alpha': 0.4836953227957089}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:26,434]\u001B[0m Trial 72 finished with value: 1.0 and parameters: {'tau': 3.812102416197474, 'alpha': 0.6931193621190901}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:27,068]\u001B[0m Trial 73 finished with value: 1.0 and parameters: {'tau': 4.666667512831364, 'alpha': 0.36501805586006975}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:27,687]\u001B[0m Trial 74 finished with value: 1.0 and parameters: {'tau': 5.6505605019231115, 'alpha': 0.6689395476075025}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:28,338]\u001B[0m Trial 75 finished with value: 1.0 and parameters: {'tau': 5.982739755564378, 'alpha': 0.633955232045263}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:28,953]\u001B[0m Trial 76 finished with value: 1.0 and parameters: {'tau': 6.273239620064288, 'alpha': 0.30871785286946096}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:29,575]\u001B[0m Trial 77 finished with value: 1.0 and parameters: {'tau': 5.248293707446692, 'alpha': 0.7511350683721781}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:30,209]\u001B[0m Trial 78 finished with value: 1.0 and parameters: {'tau': 3.0996290146034067, 'alpha': 0.766683534823707}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:30,943]\u001B[0m Trial 79 finished with value: 1.0 and parameters: {'tau': 7.17602429655014, 'alpha': 0.28449905954926513}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:31,621]\u001B[0m Trial 80 finished with value: 1.0 and parameters: {'tau': 6.7777977361096164, 'alpha': 0.22500773801272822}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:32,305]\u001B[0m Trial 81 finished with value: 1.0 and parameters: {'tau': 6.627504050445359, 'alpha': 0.33227445742475825}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:32,964]\u001B[0m Trial 82 finished with value: 1.0 and parameters: {'tau': 0.5201090334776748, 'alpha': 0.8539669687629505}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:33,532]\u001B[0m Trial 83 finished with value: 1.0 and parameters: {'tau': 0.4350815018132529, 'alpha': 0.30818556914756534}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:34,115]\u001B[0m Trial 84 finished with value: 1.0 and parameters: {'tau': 7.460512965398877, 'alpha': 0.45037904990702016}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:34,714]\u001B[0m Trial 85 finished with value: 1.0 and parameters: {'tau': 8.052551302845602, 'alpha': 0.37509415536832424}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:35,358]\u001B[0m Trial 86 finished with value: 1.0 and parameters: {'tau': 8.450218771662916, 'alpha': 0.4643240634314465}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:35,985]\u001B[0m Trial 87 finished with value: 1.0 and parameters: {'tau': 8.900709981707976, 'alpha': 0.5324718357291568}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:36,581]\u001B[0m Trial 88 finished with value: 1.0 and parameters: {'tau': 7.68222765378872, 'alpha': 0.39336946628229996}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:37,134]\u001B[0m Trial 89 finished with value: 1.0 and parameters: {'tau': 8.890707246536376, 'alpha': 0.4187628923495054}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:37,807]\u001B[0m Trial 90 finished with value: 1.0 and parameters: {'tau': 9.539139158400724, 'alpha': 0.5042887144280181}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:38,530]\u001B[0m Trial 91 finished with value: 1.0 and parameters: {'tau': 1.1037479477724268, 'alpha': 0.2520722955469823}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:39,153]\u001B[0m Trial 92 finished with value: 1.0 and parameters: {'tau': 0.9443411416222204, 'alpha': 0.5649730007216371}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:39,786]\u001B[0m Trial 93 finished with value: 1.0 and parameters: {'tau': 0.7756244058674496, 'alpha': 0.5354846451260211}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:40,415]\u001B[0m Trial 94 finished with value: 1.0 and parameters: {'tau': 0.22386873397452556, 'alpha': 0.7875618093922173}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:41,060]\u001B[0m Trial 95 finished with value: 1.0 and parameters: {'tau': 1.6014330338884109, 'alpha': 0.8628326681068483}. Best is trial 21 with value: 0.6186870899071061.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:41,682]\u001B[0m Trial 96 finished with value: 0.5615478155238243 and parameters: {'tau': 0.05020946376592769, 'alpha': 0.15342193085480144}. Best is trial 96 with value: 0.5615478155238243.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:42,301]\u001B[0m Trial 97 finished with value: 1.0 and parameters: {'tau': 1.4371795679479795, 'alpha': 0.15066756892269145}. Best is trial 96 with value: 0.5615478155238243.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:42,941]\u001B[0m Trial 98 finished with value: 1.0 and parameters: {'tau': 0.05549047045435272, 'alpha': 0.7178651495546691}. Best is trial 96 with value: 0.5615478155238243.\u001B[0m\n",
      "\u001B[32m[I 2022-05-25 18:33:43,543]\u001B[0m Trial 99 finished with value: 1.0 and parameters: {'tau': 1.8576169275138184, 'alpha': 0.5955148907944673}. Best is trial 96 with value: 0.5615478155238243.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SMAPE gradient\n",
      "Number of finished trials: 100\n",
      "Best trial: {'tau': 0.05020946376592769, 'alpha': 0.15342193085480144}\n",
      "Best score: 0.5615478155238243\n"
     ]
    }
   ],
   "source": [
    "studySMAPE = optuna.create_study(direction='minimize')\n",
    "studySMAPE.optimize(lambda trial : objective_gradient(trial, diff_smape, error(x_train, y_train, smape), smape), n_trials=100)\n",
    "\n",
    "print('Testing SMAPE gradient')\n",
    "print('Number of finished trials:', len(studySMAPE.trials))\n",
    "print('Best trial:', studySMAPE.best_trial.params)\n",
    "print('Best score:', studySMAPE.best_trial.value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Тестирование"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### График зависимости ошибки SMAPE и MSE на тестовом множестве от параметра регуляризации для метода наименьших квадратов"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "smapeList = []\n",
    "mseList = []\n",
    "for i in range(1, 100):\n",
    "    w = mnk(x_train, y_train, 1 / i)\n",
    "    mse_err = sum(sum(mse(y, np.dot(x, w)) for x, y in zip(x_test, y_test))) / len(x_test)\n",
    "    smape_err = sum(sum(smape(y, np.dot(x, w)) for x, y in zip(x_test, y_test))) / len(x_test)\n",
    "    smapeList.append(smape_err)\n",
    "    mseList.append(mse_err)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot([1 / i for i in range(1, 100)], smapeList, label='smape')\n",
    "plt.plot([1 / i for i in range(1, 100)], mseList, label='mse')\n",
    "plt.legend()\n",
    "plt.ylabel(\"metric\")\n",
    "plt.xlabel(\"tau\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### график зависимости экспоненциального скользящего среднего эмпирического риска на тренировочном множестве для градиентных спусков"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "_, w_mse = stochastic_gradient(x_train, y_train, diff_mse, studyMSE.best_trial.params['tau'], studyMSE.best_trial.params['alpha'], mse)\n",
    "_, w_smape = stochastic_gradient(x_train, y_train, diff_smape, studySMAPE.best_trial.params['tau'], studySMAPE.best_trial.params['alpha'], smape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i + 1 for i in range(0, len((w_smape)))], w_smape, label='mse')\n",
    "plt.legend()\n",
    "plt.ylabel(\"metric\")\n",
    "plt.xlabel(\"iter\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i + 1 for i in range(0, len(w_mse))], w_mse, label='smape')\n",
    "plt.legend()\n",
    "plt.ylabel(\"metric\")\n",
    "plt.xlabel(\"iter\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Оцените каждый из трёх методов на тестовом множестве данных при помощи NRMSE и SMAPE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def nrmse_methods(w):\n",
    "    ans = 0\n",
    "    y_max = np.max(y_test)\n",
    "    y_min = np.min(y_test)\n",
    "    for i in range(len(x_test)):\n",
    "        actual = np.dot(x_test.iloc[i], w)\n",
    "        ans += (actual - y_test[i]) ** 2\n",
    "    return math.sqrt(ans / len(x_test)) / (y_max - y_min)\n",
    "\n",
    "\n",
    "def smape_methods(w):\n",
    "    return sum(sum(smape(y, np.dot(x, w)) for x, y in zip(x_test, y_test))) / len(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNK: SMAPE:  0.2940588481464574 , NRMSE: 0.0002586782917400415\n",
      "MSE: SMAPE:  0.1992947191403588 , NRMSE: 0.26943824289774304\n",
      "SMAPE: SMAPE:  0.09220725690123495 , NRMSE: 0.2583796752650631\n"
     ]
    }
   ],
   "source": [
    "w_mnk = mnk(x_train, y_train, studyMNK.best_trial.params['tau'])\n",
    "w_mse, _ = stochastic_gradient(x_train, y_train, diff_mse, studyMSE.best_trial.params['tau'], studyMSE.best_trial.params['alpha'], mse)\n",
    "w_smape, _ = stochastic_gradient(x_train, y_train, diff_smape, studySMAPE.best_trial.params['tau'], studySMAPE.best_trial.params['alpha'], smape)\n",
    "\n",
    "print('MNK: SMAPE: ', smape_methods(w_mnk) , ', NRMSE:', nrmse_methods(w_mnk))\n",
    "print('MSE: SMAPE: ', smape_methods(w_mse) , ', NRMSE:', nrmse_methods(w_mse))\n",
    "print('SMAPE: SMAPE: ', smape_methods(w_smape) , ', NRMSE:', nrmse_methods(w_smape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}